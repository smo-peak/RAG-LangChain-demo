# LangChain Demo with Mistral AI ğŸš€

## ğŸ“Œ Objectif du Projet
Ce projet est un dÃ©monstrateur utilisant **LangChain** et **Mistral 7B via Ollama** pour assister lâ€™analyse de documents.

## ğŸ“‚ Architecture
L'architecture de ce projet est conÃ§ue pour fournir une analyse approfondie des documents en utilisant des techniques avancÃ©es de traitement du langage naturel (NLP) et de machine learning. Voici les principaux composants :

- **Analyse de documents** : Extraction des insights et KPIs Ã  partir des documents fournis.
- **Comparaison stratÃ©gique** : Alignement des informations extraites avec les objectifs business.
- **GÃ©nÃ©ration automatique de recommandations** : Propositions de ROI, Impact COâ‚‚, et Roadmap basÃ©es sur les analyses.

### Base de DonnÃ©es Vectorielle
Nous utilisons une base de donnÃ©es vectorielle pour stocker et rechercher efficacement les reprÃ©sentations vectorielles des documents. Chaque document est transformÃ© en un vecteur Ã  l'aide de modÃ¨les NLP, ce qui permet des recherches sÃ©mantiques rapides et prÃ©cises.

### DÃ©coupage en Chunks
Pour gÃ©rer les documents volumineux, nous les dÃ©coupons en morceaux plus petits appelÃ©s "chunks". Chaque chunk est ensuite analysÃ© individuellement, ce qui permet une meilleure gestion de la mÃ©moire et une analyse plus fine des sections spÃ©cifiques du document.

## ğŸ› ï¸ Installation

### PrÃ©requis
- **Python 3.10**
- **Docker** et **Docker Compose**
- **Git**

### Ã‰tapes d'installation

1. **Clonez le repo :**
   ```bash
   git clone https://github.com/smo-peak/RAG-LangChain-demo.git
   cd langchain-demo-esn
   ```

2. **Installez les dÃ©pendances Python :**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurez les variables d'environnement :**
   CrÃ©ez un fichier `.env` Ã  la racine du projet avec le contenu suivant :
   ```env
   MINIO_ACCESS_KEY=admin
   MINIO_SECRET_KEY=password
   MINIO_ENDPOINT=http://localhost:9000
   CHROMA_DB_PATH=chroma_db
   OLLAMA_MODEL=mistral
   OLLAMA_MEMORY_LIMIT=10GB
   ```

4. **Lancez les services Docker :**
   ```bash
   docker-compose up -d
   ```

5. **Initialisez le projet :**
   ```bash
   bash setup.sh
   ```

6. **Lancez le projet :**
   ```bash
   python main.py
   ```

## ğŸš€ Utilisation

### API
L'API est accessible Ã  l'adresse `http://localhost:5010`. Voici quelques endpoints utiles :

- **Ajouter un document :**
  ```http
  POST /add_document/
  {
    "doc_id": "unique_document_id",
    "content": "Contenu du document",
    "metadata": {
      "author": "Auteur",
      "category": "CatÃ©gorie",
      "source": "Source"
    }
  }
  ```

- **Rechercher des documents :**
  ```http
  POST /search_documents/
  {
    "query": "Votre requÃªte",
    "n_results": 3
  }
  ```

- **VÃ©rifier le statut de traitement d'un document :**
  ```http
  GET /status/{doc_id}
  ```

- **RÃ©cupÃ©rer les versions d'un document :**
  ```http
  GET /document_versions/{doc_id}
  ```

### Interface Utilisateur
L'interface utilisateur est accessible Ã  l'adresse `http://localhost:8501`.

## ğŸ³ Docker

### Construire et lancer les conteneurs
```bash
docker-compose up --build
```

### ArrÃªter les conteneurs
```bash
docker-compose down
```

## ğŸ“œ Licence
Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“ Auteurs
- **StÃ©phane MOREL** - *Initial work* - [smo-peak](https://github.com/smo-peak)

Merci d'utiliser cette Demo  ! ğŸš€